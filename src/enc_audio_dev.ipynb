{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import safetensors.torch\n",
    "import json\n",
    "from stable_audio_tools.models.factory import create_pretransform_from_config\n",
    "from stable_audio_tools import get_pretrained_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d78253a5ea64d568fdbec09ecf2e6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduardo/Projects/pre_encode_audio/pre_encode_env/lib/python3.9/site-packages/x_transformers/x_transformers.py:435: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/eduardo/Projects/pre_encode_audio/pre_encode_env/lib/python3.9/site-packages/x_transformers/x_transformers.py:461: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/eduardo/Projects/pre_encode_audio/pre_encode_env/lib/python3.9/site-packages/stable_audio_tools/models/transformer.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/eduardo/Projects/pre_encode_audio/pre_encode_env/lib/python3.9/site-packages/stable_audio_tools/models/transformer.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'flash_attn'\n",
      "flash_attn not installed, disabling Flash Attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduardo/Projects/pre_encode_audio/pre_encode_env/lib/python3.9/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/eduardo/Projects/pre_encode_audio/pre_encode_env/lib/python3.9/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:619: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/home/eduardo/Projects/pre_encode_audio/pre_encode_env/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Download model\n",
    "model, model_config = get_pretrained_model(\"stabilityai/stable-audio-open-1.0\")\n",
    "sample_rate = model_config[\"sample_rate\"]\n",
    "sample_size = model_config[\"sample_size\"]\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Save pretransform\n",
    "pretransform = model.pretransform\n",
    "pretransform_state_dict = model.pretransform.state_dict()\n",
    "\n",
    "file_path = 'pretransform.safetensors'\n",
    "safetensors.torch.save_file(pretransform_state_dict, file_path)\n",
    "\n",
    "# Load the pretransform configuration\n",
    "pretransform_config_path = 'model_config.json'\n",
    "with open(pretransform_config_path) as f:\n",
    "    pretransform_config = json.load(f)\n",
    "\n",
    "# Create the pretransform model from the configuration\n",
    "# pretransform_config['chunked'] = False\n",
    "reload_pretransform = create_pretransform_from_config(pretransform_config, sample_rate=model_config[\"sample_rate\"])\n",
    "reload_pretransform = reload_pretransform.to(device)\n",
    "\n",
    "# Check if the original pretransform and the reloaded pretransform are of the same type\n",
    "print(type(pretransform) == type(reload_pretransform))  # Should print True\n",
    "\n",
    "# Apply the state dictionary to the pretransform model\n",
    "state_dict = safetensors.torch.load_file(file_path)\n",
    "new_state_dict = {}\n",
    "for key, value in state_dict.items():\n",
    "    new_key = key.replace('model.', '')  # 'model.'\n",
    "    new_state_dict[new_key] = value\n",
    "\n",
    "reload_pretransform.load_state_dict(new_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/babyslakh_16k/Track00001/mix.wav\n",
      "torch.Size([1, 64, 5202])\n",
      "tensor(-0.1301, device='cuda:1')\n",
      "tensor(1.0509, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00002/mix.wav\n",
      "torch.Size([1, 64, 4100])\n",
      "tensor(-0.1283, device='cuda:1')\n",
      "tensor(1.0582, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00003/mix.wav\n",
      "torch.Size([1, 64, 4710])\n",
      "tensor(-0.0863, device='cuda:1')\n",
      "tensor(1.0987, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00004/mix.wav\n",
      "torch.Size([1, 64, 5009])\n",
      "tensor(-0.1086, device='cuda:1')\n",
      "tensor(1.0503, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00005/mix.wav\n",
      "torch.Size([1, 64, 5323])\n",
      "tensor(-0.1147, device='cuda:1')\n",
      "tensor(1.0661, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00006/mix.wav\n",
      "torch.Size([1, 64, 5305])\n",
      "tensor(-0.0934, device='cuda:1')\n",
      "tensor(1.0844, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00007/mix.wav\n",
      "torch.Size([1, 64, 5316])\n",
      "tensor(-0.0822, device='cuda:1')\n",
      "tensor(1.1113, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00008/mix.wav\n",
      "torch.Size([1, 64, 5591])\n",
      "tensor(-0.1165, device='cuda:1')\n",
      "tensor(1.1013, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00009/mix.wav\n",
      "torch.Size([1, 64, 3459])\n",
      "tensor(-0.1084, device='cuda:1')\n",
      "tensor(1.1350, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00010/mix.wav\n",
      "torch.Size([1, 64, 3917])\n",
      "tensor(-0.0940, device='cuda:1')\n",
      "tensor(1.0758, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00011/mix.wav\n",
      "torch.Size([1, 64, 4263])\n",
      "tensor(-0.0640, device='cuda:1')\n",
      "tensor(1.1369, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00012/mix.wav\n",
      "torch.Size([1, 64, 6627])\n",
      "tensor(-0.0494, device='cuda:1')\n",
      "tensor(1.0403, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00013/mix.wav\n",
      "torch.Size([1, 64, 4785])\n",
      "tensor(-0.0895, device='cuda:1')\n",
      "tensor(1.1147, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00014/mix.wav\n",
      "torch.Size([1, 64, 5905])\n",
      "tensor(-0.1176, device='cuda:1')\n",
      "tensor(1.0666, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00015/mix.wav\n",
      "torch.Size([1, 64, 5318])\n",
      "tensor(-0.1190, device='cuda:1')\n",
      "tensor(1.1070, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00016/mix.wav\n",
      "torch.Size([1, 64, 4366])\n",
      "tensor(-0.0216, device='cuda:1')\n",
      "tensor(1.1102, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00017/mix.wav\n",
      "torch.Size([1, 64, 6757])\n",
      "tensor(-0.1384, device='cuda:1')\n",
      "tensor(1.0654, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00018/mix.wav\n",
      "torch.Size([1, 64, 6391])\n",
      "tensor(-0.0844, device='cuda:1')\n",
      "tensor(1.0630, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00019/mix.wav\n",
      "torch.Size([1, 64, 4990])\n",
      "tensor(-0.0623, device='cuda:1')\n",
      "tensor(1.1221, device='cuda:1')\n",
      "./data/babyslakh_16k/Track00020/mix.wav\n",
      "torch.Size([1, 64, 7489])\n",
      "tensor(-0.1247, device='cuda:1')\n",
      "tensor(1.1413, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "# Define the path to the audio file\n",
    "audio_file_path = lambda x: f'./data/babyslakh_16k/Track000{x}/mix.wav'\n",
    "base_path = lambda x: f'./data/babyslakh_16k/Track000{x}/'\n",
    "outputs = './data/latents/'\n",
    "for x in range(1, 21):\n",
    "# Load the audio file\n",
    "    num = str(x)\n",
    "    num = num if len(num) > 1 else f'0{num}'\n",
    "    print(audio_file_path(num))\n",
    "    waveform, sample_rate = torchaudio.load(audio_file_path(num), )\n",
    "\n",
    "    waveform = waveform.to(device=device)\n",
    "    preprocessed_audio = reload_pretransform.model.preprocess_audio_for_encoder(waveform, sample_rate)\n",
    "    # print(preprocessed_audio.shape)\n",
    "    latent = reload_pretransform.encode(preprocessed_audio)\n",
    "    print(latent.shape)\n",
    "    print(latent.mean())\n",
    "    print(latent.var())\n",
    "    with open(base_path(num) + 'latent.npy', 'wb') as outfile:\n",
    "        latent.cpu().numpy().tofile(outfile)\n",
    "    with open(outputs + f'Track000{num}_' + 'latent.npy', 'wb') as outfile:\n",
    "        latent.cpu().numpy().tofile(outfile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
